{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05078955-215a-497d-a911-8b18265fcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa88cd1-7e19-427a-b90f-146fcb37023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../completed/df_stats.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a7753-df45-4c5e-825b-8f6b0d8e4587",
   "metadata": {},
   "source": [
    "## 2.1 Analisi Statistica e Regressione (Inference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1e27f-a5e6-450b-8fa4-64cd7848c26e",
   "metadata": {},
   "source": [
    "In questa parte, l'attenzione è posta sulla significatività statistica e sull'interpretazione dei coefficienti. Non stiamo ancora cercando di fare la \"miglior predizione possibile\", ma di capire come le variabili si influenzano a vicenda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2843e2d-6acb-490c-a755-2cfbde95a190",
   "metadata": {},
   "source": [
    "**Selezione delle variabili**  \n",
    "Come sappiamo il **target** è Price, e il resto sono i nostri **predittori**. Naturalmente cercheremo di investigare sulla significatività statistica di ogni coefficiente, e quindi potremmo dover cambiare alcune scelte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f8c43-0fac-4323-84db-6a43b3b4b965",
   "metadata": {},
   "source": [
    "Applichiamo utilizzando la libreria **statsModels** il nostro modello di **Regressione Lineare.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128e51d6-a77d-47c7-bd03-37c518d7d3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.932\n",
      "Model:                            OLS   Adj. R-squared:                  0.932\n",
      "Method:                 Least Squares   F-statistic:                     2171.\n",
      "Date:                Fri, 26 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        09:29:04   Log-Likelihood:                 1362.4\n",
      "No. Observations:                5710   AIC:                            -2651.\n",
      "Df Residuals:                    5673   BIC:                            -2405.\n",
      "Df Model:                          36                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -0.8504      0.170     -5.002      0.000      -1.184      -0.517\n",
      "Age                    -0.0962      0.001    -75.846      0.000      -0.099      -0.094\n",
      "Kilometers_Driven      -0.0717      0.005    -14.953      0.000      -0.081      -0.062\n",
      "Fuel_Type              -0.1842      0.009    -19.732      0.000      -0.203      -0.166\n",
      "Transmission            0.0745      0.008      8.909      0.000       0.058       0.091\n",
      "Owner_Type             -0.0533      0.007     -8.185      0.000      -0.066      -0.041\n",
      "Mileage                -0.0121      0.001     -9.422      0.000      -0.015      -0.010\n",
      "Engine                  0.2289      0.028      8.213      0.000       0.174       0.284\n",
      "Power                   0.6838      0.020     34.475      0.000       0.645       0.723\n",
      "Seats                   0.0251      0.005      4.957      0.000       0.015       0.035\n",
      "Brand_BMW              -0.0224      0.018     -1.279      0.201      -0.057       0.012\n",
      "Brand_Chevrolet        -0.7695      0.024    -32.276      0.000      -0.816      -0.723\n",
      "Brand_Ford             -0.5887      0.019    -30.494      0.000      -0.627      -0.551\n",
      "Brand_Honda            -0.5838      0.018    -33.352      0.000      -0.618      -0.549\n",
      "Brand_Hyundai          -0.5560      0.017    -32.881      0.000      -0.589      -0.523\n",
      "Brand_Land              0.2888      0.030      9.687      0.000       0.230       0.347\n",
      "Brand_Mahindra         -0.6903      0.021    -32.778      0.000      -0.732      -0.649\n",
      "Brand_Maruti           -0.4893      0.018    -27.308      0.000      -0.524      -0.454\n",
      "Brand_Mercedes-Benz     0.0165      0.017      0.978      0.328      -0.017       0.050\n",
      "Brand_Nissan           -0.5789      0.026    -22.347      0.000      -0.630      -0.528\n",
      "Brand_Other            -0.5788      0.026    -22.101      0.000      -0.630      -0.527\n",
      "Brand_Other_Luxury      0.1352      0.023      5.917      0.000       0.090       0.180\n",
      "Brand_Renault          -0.5761      0.022    -25.612      0.000      -0.620      -0.532\n",
      "Brand_Skoda            -0.5385      0.020    -26.472      0.000      -0.578      -0.499\n",
      "Brand_Tata             -0.8273      0.022    -37.701      0.000      -0.870      -0.784\n",
      "Brand_Toyota           -0.3593      0.019    -18.498      0.000      -0.397      -0.321\n",
      "Brand_Volkswagen       -0.5901      0.019    -31.357      0.000      -0.627      -0.553\n",
      "Location_Bangalore      0.1305      0.017      7.746      0.000       0.097       0.164\n",
      "Location_Chennai        0.0270      0.016      1.688      0.091      -0.004       0.058\n",
      "Location_Coimbatore     0.0948      0.015      6.149      0.000       0.065       0.125\n",
      "Location_Delhi         -0.0646      0.016     -4.153      0.000      -0.095      -0.034\n",
      "Location_Hyderabad      0.1051      0.015      6.980      0.000       0.076       0.135\n",
      "Location_Jaipur        -0.0131      0.016     -0.798      0.425      -0.045       0.019\n",
      "Location_Kochi         -0.0266      0.015     -1.730      0.084      -0.057       0.004\n",
      "Location_Kolkata       -0.1943      0.016    -12.347      0.000      -0.225      -0.163\n",
      "Location_Mumbai        -0.0615      0.015     -4.091      0.000      -0.091      -0.032\n",
      "Location_Pune          -0.0325      0.016     -2.095      0.036      -0.063      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                     1718.146   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            46756.586\n",
      "Skew:                          -0.848   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.916   Cond. No.                     1.64e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.64e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y_inference = df['Price']\n",
    "\n",
    "vars_da_escludere = ['Price'] \n",
    "X_inference = df.drop(columns=vars_da_escludere)\n",
    "\n",
    "X_inference = sm.add_constant(X_inference)\n",
    "\n",
    "modello = sm.OLS(y_inference, X_inference).fit()\n",
    "\n",
    "print(modello.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87e42e-ff62-43e0-b94b-6a18381f94d9",
   "metadata": {},
   "source": [
    "**1. Analisi della Bontà di Adattamento (R-squared)**  \n",
    "R-squared (0.932): Il modello spiega il 93.2% della varianza totale dei prezzi. Questo indica un adattamento eccellente ai dati.  \n",
    "Prob (F-statistic) (0.00): Indica che il modello nel suo complesso è statisticamente significativo (non è un risultato casuale).  \n",
    "Adj. R-squared (0.932): È identico all'R-squared semplice. Significa che non abbiamo \"gonfiato\" il modello con variabili inutili (spazzatura). Tutte le variabili aggiunte portano informazione.\n",
    "\n",
    "**2. Diagnostica: Il problema della Multicollinearità**  \n",
    "Nelle note:  \n",
    "The condition number is large, 1.64e+03. This might indicate that there are strong multicollinearity...\n",
    "\n",
    "Avevamo ragione a temere Engine + Power. Il numero è alto, il che significa che le due variabili \"litigano\" un po'. Tuttavia, guardando i P-value, entrambe sono rimaste significative (0.000) e hanno coefficienti positivi.  \n",
    "**Interpretazione**: Nonostante la collinearità, il modello beneficia dell'inclusione di entrambe le variabili per massimizzare la precisione (R2), sebbene l'interpretazione dei singoli coefficienti di potenza e cilindrata vada fatta con cautela.  \n",
    "\n",
    "**3. Interpretazione dei Coefficienti**  \n",
    "- A. Variabili di Usura (Age, Km)  \n",
    "Age (Coef: -0.0962):  \n",
    "Mantenendo costanti le altre variabili, ogni anno di invecchiamento dell'auto è associato a una riduzione del prezzo di circa il 9.6%. Questo rispecchia fedelmente il deprezzamento annuale di mercato.  \n",
    "Kilometers_Driven (Coef: -0.0717):  \n",
    "L'usura chilometrica ha un impatto negativo significativo: all'aumentare dei chilometri, il valore diminuisce.  \n",
    "\n",
    "- B. Variabili di Performance (Power, Engine)  \n",
    "Power (Coef: 0.6838):  \n",
    "La potenza è il predittore positivo più forte. Un motore più potente è associato drasticamente a un prezzo più alto.  \n",
    "\n",
    "- C. Variabili Categoriche (Brand e Trasmissione)\n",
    "Le variabili Dummy funzionano per confronto con una base. Quale Brand manca nella lista? Audi. Quindi tutti i numeri sono rispetto ad un'Audi:  \n",
    "Brand_BMW (P-value 0.201, Coef -0.02):  \n",
    "Il coefficiente non è statisticamente significativo (P > 0.05). Questo significa che, a parità di età e potenza, non c'è differenza di prezzo statistica tra una BMW e un'Audi (il brand di riferimento). Il mercato le valuta uguali.  \n",
    "Brand_Maruti (Coef: -0.4893):  \n",
    "Il coefficiente è negativo e significativo. Rispetto al brand di riferimento (Audi), una Maruti vale circa il 49% in meno a parità di altre caratteristiche.  \n",
    "Transmission (Coef: 0.0745):\n",
    "Passare dal cambio Manuale (0) all'Automatico (1) comporta un incremento di prezzo del 7.5% circa, confermando il valore aggiunto della trasmissione automatica.  \n",
    "\n",
    "**4. Analisi dei P-Value**  \n",
    "Promossi (Significativi, P < 0.05): Age, Km, Fuel, Transmission, Power, Engine, Seats e la maggior parte dei Brand economici (Maruti, Hyundai, ecc.). Queste variabili devono restare nel modello.  \n",
    "\n",
    "Bocciati o Neutri (Non Significativi, P > 0.05):  \n",
    "Brand_BMW (0.201), Brand_Mercedes-Benz (0.328), Location_Jaipur, Chennai, Kochi.  \n",
    "Significato: Questo non vuol dire che \"non contano\", ma che non sono diverse dalla media o dal riferimento (Audi). E inoltre ha senso che BMW e Mercedes siano simili ad Audi.\n",
    "\n",
    "**5. Analisi degli Intervalli di Confidenza ([0.025 0.975])**  \n",
    "Diamo una visione generale su quelli più rilevanti:  \n",
    "Guardiamo la riga di Age:  \n",
    "Coefficiente stimato: -0.0962. Intervallo: [-0.099, -0.094].  \n",
    "Commento: L'intervallo è strettissimo (i due numeri sono vicinissimi). Questo indica una grandissima precisione della stima. Siamo estremamente certi che il deprezzamento annuo sia tra il 9.4% e il 9.9%.  \n",
    "Guardiamo la riga di Brand_BMW:  \n",
    "Intervallo: [-0.057, 0.012].  \n",
    "Commento: L'intervallo contiene lo zero (va da negativo a positivo). Ecco perché il P-value è alto, non siamo sicuri se il brand BMW aggiunga o tolga valore rispetto alla base. Statisticamente, l'effetto è nullo.  \n",
    "Power: L'intervallo è [0.645, 0.723].  \n",
    "Interpretazione: Anche per la potenza la stima è solida. L'effetto positivo sul prezzo è netto e ben definito.  \n",
    "\n",
    "La maggior parte degli intervalli di confidenza sono ristretti e non includono lo zero, il che indica che le stime dei coefficienti sono precise e affidabili. Le uniche eccezioni, riguardano brand di lusso comparabili al riferimento o location specifiche, dove l'effetto prezzo è statisticamente trascurabile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182192e8-8338-4b5c-8cdc-f76da00e1b01",
   "metadata": {},
   "source": [
    "## 2.2 Analisi Predittiva e Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485be11-2b02-4f48-ab09-db26d5ea218b",
   "metadata": {},
   "source": [
    "### 2.2.1 Definizione del Problema e del Valore Pratico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887b2c8-b268-4eb1-ad96-e45d89d980cd",
   "metadata": {},
   "source": [
    "**Titolo del Progetto**: Algoritmo di Pricing per il mercato delle automobili (\"AutoPrice AI\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bcef6-53a6-44d4-b1bc-0767e0244bc6",
   "metadata": {},
   "source": [
    "**1. Scenario Applicativo**  \n",
    "Immaginiamo di integrare questo modello predittivo all'interno di una piattaforma web di compravendita auto o nel gestionale interno di una grande concessionaria di auto usate. Quando un utente inserisce i dati tecnici di una vettura, il sistema utilizza l'algoritmo di **Machine Learning** per calcolare in tempo reale il **Price** dell'auto, senza intervento umano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5119b9-0f98-4bad-96e9-99bb631316b5",
   "metadata": {},
   "source": [
    "**2. Utilità del Problema (Perché risolverlo?)**  \n",
    "Il mercato delle auto usate soffre di una forte asimmetria informativa:  \n",
    "- Chi vende spesso non sa quanto vale la sua auto: rischia di svenderla o di proporla a un prezzo fuori mercato.  \n",
    "- Chi compra ha paura di pagare troppo o di essere truffato.  \n",
    "- Può essere utile per i concessionari, per stabilire un prezzo che è più basato sul mercato corrente.  \n",
    "Questo strumento risolve il problema fornendo una valutazione oggettiva, immediata e basata sui dati reali di migliaia di transazioni simili, aggiungendo certezze al soggetto interessato. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aff86e-84a2-4803-8fee-46cd5aee586b",
   "metadata": {},
   "source": [
    "**3. Quantificazione del Valore Aggiunto**  \n",
    "L'implementazione di questo modello porterebbe vantaggi tangibili:  \n",
    "- Risparmio tempo: Riduzione del tempo di valutazione da 20-30 minuti (ricerca manuale) a < 1 secondo. Per una concessionaria che valuta molteplici auto al mese, questo equivale a risparmiare moltissimo.  \n",
    "- Incremento del profitto: Evitando errori di sovrastima nell'acquisto di auto usate, il concessionario protegge il proprio margine di profitto.    \n",
    "- Fiducia del cliente: Una piattaforma online che mostra un \"Prezzo Consigliato dall'AI\" aumenta la trasparenza, incrementando la probabilità di contatto tra venditore e acquirente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e643ff4-c465-444e-8d7f-78d0ae14643e",
   "metadata": {},
   "source": [
    "Data la natura del nostro contesto (pricing), si è scelto di mantenere l'approccio di Regressione per predire il valore dell'auto, in quanto abbiamo già ricevuto dei risultati eccellenti. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d3b9c-4777-490c-8600-ed12697e1860",
   "metadata": {},
   "source": [
    "### 2.2.2 Setup Sperimentale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0e3fe-5069-4780-96c8-8b69cdbccfcc",
   "metadata": {},
   "source": [
    "**1. Preparazione e Data Splitting**  \n",
    "Dividiamo i dati in Training Set (80%) e Test Set (20%).  \n",
    "*Nota*: La validazione la faremo dopo usando la Cross-Validation automatica dentro i modelli, quindi per ora ci basta dividere in due (Train/Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccb66b2-9c8b-444d-b427-189dbb924229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebbd0192-95af-4c6b-b7bf-94ed9b8fbee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni Training Set: (4568, 36)\n",
      "Dimensioni Test Set:     (1142, 36)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Price']) \n",
    "\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dimensioni Training Set: {X_train.shape}\")\n",
    "print(f\"Dimensioni Test Set:     {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4fb17-5d2b-41db-9009-dd12e15f6ff8",
   "metadata": {},
   "source": [
    "**2. Preprocessing per ML (Scaling)**  \n",
    "Qui applichiamo lo StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd613815-692d-4710-abfb-7440ca9f4287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power</th>\n",
       "      <th>Seats</th>\n",
       "      <th>Brand_BMW</th>\n",
       "      <th>...</th>\n",
       "      <th>Location_Bangalore</th>\n",
       "      <th>Location_Chennai</th>\n",
       "      <th>Location_Coimbatore</th>\n",
       "      <th>Location_Delhi</th>\n",
       "      <th>Location_Hyderabad</th>\n",
       "      <th>Location_Jaipur</th>\n",
       "      <th>Location_Kochi</th>\n",
       "      <th>Location_Kolkata</th>\n",
       "      <th>Location_Mumbai</th>\n",
       "      <th>Location_Pune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207501</td>\n",
       "      <td>0.622293</td>\n",
       "      <td>-0.923658</td>\n",
       "      <td>1.550443</td>\n",
       "      <td>-0.433436</td>\n",
       "      <td>-0.221204</td>\n",
       "      <td>0.753583</td>\n",
       "      <td>1.263859</td>\n",
       "      <td>-0.357044</td>\n",
       "      <td>-0.214539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248163</td>\n",
       "      <td>-0.291609</td>\n",
       "      <td>2.862018</td>\n",
       "      <td>-0.32689</td>\n",
       "      <td>-0.369596</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>-0.352944</td>\n",
       "      <td>-0.321116</td>\n",
       "      <td>-0.39072</td>\n",
       "      <td>-0.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.808795</td>\n",
       "      <td>-1.089762</td>\n",
       "      <td>1.082652</td>\n",
       "      <td>-0.644977</td>\n",
       "      <td>-0.433436</td>\n",
       "      <td>0.751562</td>\n",
       "      <td>-0.743476</td>\n",
       "      <td>-0.551891</td>\n",
       "      <td>-0.357044</td>\n",
       "      <td>-0.214539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248163</td>\n",
       "      <td>-0.291609</td>\n",
       "      <td>-0.349404</td>\n",
       "      <td>3.05913</td>\n",
       "      <td>-0.369596</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>-0.352944</td>\n",
       "      <td>-0.321116</td>\n",
       "      <td>-0.39072</td>\n",
       "      <td>-0.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.131264</td>\n",
       "      <td>-0.184139</td>\n",
       "      <td>1.082652</td>\n",
       "      <td>1.550443</td>\n",
       "      <td>-0.433436</td>\n",
       "      <td>-1.923545</td>\n",
       "      <td>0.478176</td>\n",
       "      <td>1.017559</td>\n",
       "      <td>-0.357044</td>\n",
       "      <td>-0.214539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248163</td>\n",
       "      <td>-0.291609</td>\n",
       "      <td>-0.349404</td>\n",
       "      <td>3.05913</td>\n",
       "      <td>-0.369596</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>-0.352944</td>\n",
       "      <td>-0.321116</td>\n",
       "      <td>-0.39072</td>\n",
       "      <td>-0.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.546266</td>\n",
       "      <td>-0.139732</td>\n",
       "      <td>-0.923658</td>\n",
       "      <td>-0.644977</td>\n",
       "      <td>-0.433436</td>\n",
       "      <td>0.508370</td>\n",
       "      <td>-0.274000</td>\n",
       "      <td>-1.039218</td>\n",
       "      <td>-0.357044</td>\n",
       "      <td>-0.214539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248163</td>\n",
       "      <td>-0.291609</td>\n",
       "      <td>-0.349404</td>\n",
       "      <td>-0.32689</td>\n",
       "      <td>-0.369596</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>-0.352944</td>\n",
       "      <td>3.114144</td>\n",
       "      <td>-0.39072</td>\n",
       "      <td>-0.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.131264</td>\n",
       "      <td>0.309645</td>\n",
       "      <td>1.082652</td>\n",
       "      <td>1.550443</td>\n",
       "      <td>-0.433436</td>\n",
       "      <td>-0.464396</td>\n",
       "      <td>-0.070147</td>\n",
       "      <td>0.306023</td>\n",
       "      <td>-0.357044</td>\n",
       "      <td>-0.214539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248163</td>\n",
       "      <td>-0.291609</td>\n",
       "      <td>-0.349404</td>\n",
       "      <td>-0.32689</td>\n",
       "      <td>-0.369596</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>2.833314</td>\n",
       "      <td>-0.321116</td>\n",
       "      <td>-0.39072</td>\n",
       "      <td>-0.324423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Kilometers_Driven  Fuel_Type  Transmission  Owner_Type   Mileage  \\\n",
       "0  0.207501           0.622293  -0.923658      1.550443   -0.433436 -0.221204   \n",
       "1 -0.808795          -1.089762   1.082652     -0.644977   -0.433436  0.751562   \n",
       "2 -0.131264          -0.184139   1.082652      1.550443   -0.433436 -1.923545   \n",
       "3  0.546266          -0.139732  -0.923658     -0.644977   -0.433436  0.508370   \n",
       "4 -0.131264           0.309645   1.082652      1.550443   -0.433436 -0.464396   \n",
       "\n",
       "     Engine     Power     Seats  Brand_BMW  ...  Location_Bangalore  \\\n",
       "0  0.753583  1.263859 -0.357044  -0.214539  ...           -0.248163   \n",
       "1 -0.743476 -0.551891 -0.357044  -0.214539  ...           -0.248163   \n",
       "2  0.478176  1.017559 -0.357044  -0.214539  ...           -0.248163   \n",
       "3 -0.274000 -1.039218 -0.357044  -0.214539  ...           -0.248163   \n",
       "4 -0.070147  0.306023 -0.357044  -0.214539  ...           -0.248163   \n",
       "\n",
       "   Location_Chennai  Location_Coimbatore  Location_Delhi  Location_Hyderabad  \\\n",
       "0         -0.291609             2.862018        -0.32689           -0.369596   \n",
       "1         -0.291609            -0.349404         3.05913           -0.369596   \n",
       "2         -0.291609            -0.349404         3.05913           -0.369596   \n",
       "3         -0.291609            -0.349404        -0.32689           -0.369596   \n",
       "4         -0.291609            -0.349404        -0.32689           -0.369596   \n",
       "\n",
       "   Location_Jaipur  Location_Kochi  Location_Kolkata  Location_Mumbai  \\\n",
       "0        -0.269355       -0.352944         -0.321116         -0.39072   \n",
       "1        -0.269355       -0.352944         -0.321116         -0.39072   \n",
       "2        -0.269355       -0.352944         -0.321116         -0.39072   \n",
       "3        -0.269355       -0.352944          3.114144         -0.39072   \n",
       "4        -0.269355        2.833314         -0.321116         -0.39072   \n",
       "\n",
       "   Location_Pune  \n",
       "0      -0.324423  \n",
       "1      -0.324423  \n",
       "2      -0.324423  \n",
       "3      -0.324423  \n",
       "4      -0.324423  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_final = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_final = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d3e62-d1b0-43ad-a0b6-86fd2ea3c3a6",
   "metadata": {},
   "source": [
    "### 2.2.3 Modellazione e Selezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c06fab4-d7fe-4d9e-a649-c57007154428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d9875cf-58e0-4157-be4f-1e8ad910585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Linear Regression R2: 0.9429\n",
      "\n",
      "2. Ridge Regression Best R2 (CV): 0.9277\n",
      "   Miglior alpha: {'alpha': 1}\n",
      "\n",
      "3. Polynomial Regression Best R2 (CV): 0.9381\n",
      "   Miglior alpha per la Polynomial: {'ridge__alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "# --- MODELLO 1: Linear Regression emplice\n",
    "lin_reg = LinearRegression()\n",
    "# Qui non c'è grid search perché non ha iperparametri da regolare\n",
    "lin_reg.fit(X_train_final, y_train)\n",
    "score_lin = lin_reg.score(X_test_final, y_test)\n",
    "print(f\"1. Linear Regression R2: {score_lin:.4f}\")\n",
    "\n",
    "\n",
    "# --- MODELLO 2: Ridge Regression (Per gestire la collinearità Engine/Power) ---\n",
    "# Usiamo GridSearch per trovare l'alpha giusto\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10, 50, 100]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5, scoring='r2')\n",
    "ridge_grid.fit(X_train_final, y_train)\n",
    "\n",
    "print(f\"\\n2. Ridge Regression Best R2 (CV): {ridge_grid.best_score_:.4f}\")\n",
    "print(f\"   Miglior alpha: {ridge_grid.best_params_}\\n\")\n",
    "\n",
    "\n",
    "# --- MODELLO 3: Polynomial Regression\n",
    "# ATTENZIONE: Usiamo degree=2. Se metti 3 esplode il PC (troppe colonne).\n",
    "# Creiamo una Pipeline: Prima crea i quadrati delle variabili poi fa la Regressione Ridge\n",
    "# Usiamo Ridge dentro la polinomiale per evitare che i coefficienti esplodano\n",
    "\n",
    "poly_pipeline = make_pipeline(PolynomialFeatures(degree=2), Ridge())\n",
    "\n",
    "# Cerchiamo l'alpha anche qui\n",
    "poly_params = {'ridge__alpha': [1, 10, 100]}\n",
    "poly_grid = GridSearchCV(poly_pipeline, poly_params, cv=5, scoring='r2')\n",
    "\n",
    "poly_grid.fit(X_train_final, y_train)\n",
    "\n",
    "print(f\"3. Polynomial Regression Best R2 (CV): {poly_grid.best_score_:.4f}\")\n",
    "print(f\"   Miglior alpha per la Polynomial: {poly_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978ec71-53bb-420b-aa51-a0054ea21d10",
   "metadata": {},
   "source": [
    "**Scelta degli Algoritmi**:  \n",
    "\n",
    "Regressione Lineare: Utilizzata come base di riferimento per valutare le performance minime accettabili.  \n",
    "\n",
    "Ridge Regression: Selezionata specificamente per gestire la multicollinearità rilevata nell'analisi esplorativa (tra Engine e Power). La regolarizzazione L2 penalizza i coefficienti troppo alti, riducendo la varianza del modello senza eliminare variabili.  \n",
    "\n",
    "Regressione Polinomiale (Grado 2): Introdotta per catturare possibili le relazioni non lineari, nonostante le trasformazioni logaritmiche, osservate nei grafici (es. la crescita esponenziale del prezzo rispetto alla potenza)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e646996-fa5c-4f83-aee0-4aff7a982eee",
   "metadata": {},
   "source": [
    "### 2.2.4 Valutazione e Confronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9b9f416-3de1-4f4c-b70a-a87a2decbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d86a21-7941-4641-8e50-cbda60865ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VALUTAZIONE SUL TEST SET\n",
      "                           Model  R2 Score  RMSE (Log Scale)  MAE (Log Scale)\n",
      "2  Polynomial Regression (Deg 2)  0.956100          0.158417         0.118733\n",
      "1               Ridge Regression  0.942901          0.180668         0.139884\n",
      "0              Linear Regression  0.942900          0.180671         0.139885\n"
     ]
    }
   ],
   "source": [
    "models_to_evaluate = {\n",
    "    \"Linear Regression\": lin_reg,\n",
    "    \"Ridge Regression\": ridge_grid.best_estimator_,\n",
    "    \"Polynomial Regression (Deg 2)\": poly_grid.best_estimator_\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "\n",
    "print(\"--- VALUTAZIONE SUL TEST SET\")\n",
    "\n",
    "for name, model in models_to_evaluate.items():\n",
    "    y_pred_test = model.predict(X_test_final)\n",
    "    \n",
    "    # Calcola le metriche\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Salva i risultati\n",
    "    results_list.append({\n",
    "        \"Model\": name,\n",
    "        \"R2 Score\": r2,\n",
    "        \"RMSE (Log Scale)\": rmse,\n",
    "        \"MAE (Log Scale)\": mae\n",
    "    })\n",
    "\n",
    "# Crea la classifica finale\n",
    "df_results = pd.DataFrame(results_list).sort_values(by='R2 Score', ascending=False)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779828c-bb68-4fe7-8613-6bf25ca8fde9",
   "metadata": {},
   "source": [
    "**Confronto Critico**  \n",
    "- Best Model: Regressione Polinomiale (Grado 2). È il modello indiscusso, raggiungendo un $R^2$ Score di 0.956 e un RMSE di 0.158 sul Test Set. Questo miglioramento netto rispetto ai modelli lineari dimostra che la relazione tra le caratteristiche e il Price non è puramente lineare, ma presenta curvature che solo il modello polinomiale ha saputo catturare.  \n",
    "- Regressione Lineare e la Ridge Regression hanno ottenuto risultati quasi identici ($R^2 \\approx 0.943$). La GridSearch per la Ridge ha selezionato un parametro di penalizzazione molto basso ($\\alpha=1$), indicando che il modello non necessitava di una forte regolarizzazione per performare bene. Tuttavia, la Ridge rimane preferibile per la sua capacità teorica di gestire meglio la multicollinearità.  \n",
    "- È interessante notare che le performance sul Test Set ($0.94-0.95$) sono risultate leggermente superiori a quelle stimate in Cross-Validation ($0.92-0.94$). Questo fenomeno esclude problemi di Overfitting e conferma che il modello è in grado di generalizzare eccellentemente su nuovi dati mai visti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479cfdfa-e02b-4233-bb6e-99ae95c03755",
   "metadata": {},
   "source": [
    "## 2.3 Conclusioni Parziali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec6b5a-c630-4694-bc64-bd3c706c807e",
   "metadata": {},
   "source": [
    "**1. Le principali relazioni statistiche scoperte**  \n",
    "L'analisi inferenziale ha confermato la validità delle teorie economiche sul deprezzamento e ha quantificato l'impatto delle features.\n",
    "- È stata trovata una relazione negativa forte e precisa. A parità di altre condizioni, ogni anno di età riduce il valore dell'auto di circa il 9.6%.\n",
    "- La Potenza (Power) è risultata essere il predittore positivo più influente. L'analisi ha evidenziato che il mercato premia la performance in modo non-lineare.\n",
    "- La trasmissione Automatica offre un incremento di valore netto stimato intorno al 7.5% rispetto alla manuale.\n",
    "- Brands: I coefficienti delle variabili dummy hanno delineato una chiara gerarchia di mercato. I brand più economici mostrano valutazioni inferiori del 45-50% rispetto ai brand più costosi (Audi), mentre non vi è evidenza statistica significativa di differenze di prezzo tra i giganti del lusso (Audi, BMW, Mercedes), che il mercato percepisce come equivalenti.\n",
    "**2. Performance del miglior modello e applicabilità**  \n",
    "Per la fase predittiva sono stati confrontati modelli lineari (OLS, Ridge) e non lineari.\n",
    "- La Regressione Polinomiale di Grado 2 (con regolarizzazione Ridge) ha superato tutti gli altri algoritmi, raggiungendo un $R^2$ Score di 0.956 sul Test Set. Il modello è in grado di spiegare il 95.6% della varianza dei prezzi. L'errore medio (RMSE) di 0.158 indica un margine di errore percentuale medio intorno al 15-16%, un risultato eccellente.\n",
    "- Applicabilità nello scenario ipotizzato: Il modello sviluppato è pronto per essere integrato in una piattaforma per concessionari o portali web. Il modello permette in tempo reale risultati oggettivi basati sui dati storici, riducendo drasticamente i tempi d'attesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2fafd-2a16-4023-bca9-bf5922694497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
